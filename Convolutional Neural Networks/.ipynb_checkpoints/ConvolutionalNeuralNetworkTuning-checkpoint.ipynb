{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "0. If you haven't already, follow [the setup instructions here](https://jennselby.github.io/MachineLearningCourseNotes/#setting-up-python3) to get all necessary software installed.\n",
    "0. Read through the code in the following sections:\n",
    "    * [MNIST Data](#MNIST-Data)\n",
    "    * [Convolutional Neural Network Model](#Convolutional-Neural-Network-Model)\n",
    "    * [Train Model](#Train-Model)\n",
    "    * [Validation](#Validation)\n",
    "0. Complete the [Exercise](#Exercise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'tanh' from 'keras.layers' (/Users/bracho/Library/Python/3.8/lib/python/site-packages/keras/layers/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-95-a501f21edef5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvolutional\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFlatten\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mReLU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMaxPooling2D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSoftmax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtanh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSGD\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'tanh' from 'keras.layers' (/Users/bracho/Library/Python/3.8/lib/python/site-packages/keras/layers/__init__.py)"
     ]
    }
   ],
   "source": [
    "# allow matplotlib graphics to display in the notebook\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot\n",
    "\n",
    "# import numpy, for image dimension manipulation\n",
    "import numpy\n",
    "\n",
    "# import validation methods from scikit-learn\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "\n",
    "# import the dataset and neural network layers from keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers import Dense, Flatten, ReLU, MaxPooling2D, Softmax\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST Data\n",
    "[MNIST](https://en.wikipedia.org/wiki/MNIST_database) is a famous dataset of images of handwritten numbers. The goal is to be able to figure out which number is in the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants to describe the MNIST images\n",
    "NUM_ROWS = 28 \n",
    "NUM_COLUMNS = 28\n",
    "NUM_COLORS = 1\n",
    "IMG_SHAPE = (NUM_ROWS, NUM_COLUMNS, NUM_COLORS)\n",
    "\n",
    "# constant to describe the MNIST output labels\n",
    "# there are ten different numbers, 0-9\n",
    "NUM_CLASSES = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "((images_train, labels_train), (images_test, labels_test)) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at one particular image and its label, to better understand the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x14788aa60>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "matplotlib.pyplot.imshow(images_train[17], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_train[17]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 14, 14, 8)         80        \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 7, 7, 8)           584       \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 392)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 8)                 3144      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                90        \n",
      "=================================================================\n",
      "Total params: 3,898\n",
      "Trainable params: 3,898\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Original provided example model\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# convolutional layers\n",
    "model.add(Conv2D(input_shape=IMG_SHAPE,\n",
    "                 filters=8, kernel_size=3, strides=2, padding='same'))\n",
    "model.add(Conv2D(filters=8, kernel_size=3, strides=2, padding='same'))\n",
    "\n",
    "# dense layers to consolidate information\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=8, activation='tanh'))\n",
    "\n",
    "# output layer to make the final decision on which number it is\n",
    "model.add(Dense(units=NUM_CLASSES, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_64 (Conv2D)           (None, 28, 28, 16)        160       \n",
      "_________________________________________________________________\n",
      "re_lu_55 (ReLU)              (None, 28, 28, 16)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_62 (MaxPooling (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_65 (Conv2D)           (None, 14, 14, 32)        4640      \n",
      "_________________________________________________________________\n",
      "re_lu_56 (ReLU)              (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_63 (MaxPooling (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_66 (Conv2D)           (None, 7, 7, 64)          18496     \n",
      "_________________________________________________________________\n",
      "re_lu_57 (ReLU)              (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_64 (MaxPooling (None, 3, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_23 (Flatten)         (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 128)               73856     \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 106,058\n",
      "Trainable params: 106,058\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# First convolutional model\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# convolutional layers\n",
    "model.add(Conv2D(input_shape=IMG_SHAPE,\n",
    "                 filters=8, kernel_size=3, strides=1, padding='same'))\n",
    "model.add(ReLU())\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Conv2D(filters=8, kernel_size=3, strides=1, padding='same'))\n",
    "model.add(ReLU())\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "# dense layers to consolidate information\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=32, activation='tanh'))\n",
    "\n",
    "# output layer to make the final decision on which number it is\n",
    "model.add(Dense(units=NUM_CLASSES, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 14, 14, 4)         40        \n",
      "_________________________________________________________________\n",
      "re_lu_2 (ReLU)               (None, 14, 14, 4)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 3, 3, 4)           0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 36)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 64)                2368      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 3,058\n",
      "Trainable params: 3,058\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Second one-layer convolutional model with fewer parameters than the original\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# convolutional layers\n",
    "model.add(Conv2D(input_shape=IMG_SHAPE,\n",
    "                 filters=4, kernel_size=3, strides=2, padding='same'))\n",
    "model.add(ReLU())\n",
    "model.add(MaxPooling2D(pool_size=(4,4)))\n",
    "\n",
    "# dense layers to consolidate information\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=64, activation='tanh'))\n",
    "\n",
    "# output layer to make the final decision on which number it is\n",
    "model.add(Dense(units=NUM_CLASSES, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_22 (Conv2D)           (None, 28, 28, 16)        160       \n",
      "_________________________________________________________________\n",
      "re_lu_20 (ReLU)              (None, 28, 28, 16)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 14, 14, 16)        2320      \n",
      "_________________________________________________________________\n",
      "re_lu_21 (ReLU)              (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling (None, 7, 7, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 7, 7, 16)          2320      \n",
      "_________________________________________________________________\n",
      "re_lu_22 (ReLU)              (None, 7, 7, 16)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling (None, 3, 3, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 3, 3, 16)          2320      \n",
      "_________________________________________________________________\n",
      "re_lu_23 (ReLU)              (None, 3, 3, 16)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_23 (MaxPooling (None, 1, 1, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 10)                170       \n",
      "=================================================================\n",
      "Total params: 7,290\n",
      "Trainable params: 7,290\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# First convolutional model\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# convolutional layers\n",
    "model.add(Conv2D(input_shape=IMG_SHAPE,\n",
    "                 filters=16, kernel_size=3, strides=1, padding='same'))\n",
    "model.add(ReLU())\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Conv2D(filters=16, kernel_size=3, strides=1, padding='same'))\n",
    "model.add(ReLU())\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Conv2D(filters=16, kernel_size=3, strides=1, padding='same'))\n",
    "model.add(ReLU())\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Conv2D(filters=16, kernel_size=3, strides=1, padding='same'))\n",
    "model.add(ReLU())\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "\n",
    "# dense layers to consolidate information\n",
    "model.add(Flatten())\n",
    "\n",
    "# output layer to make the final decision on which number it is\n",
    "model.add(Dense(units=NUM_CLASSES, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_42 (Conv2D)           (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "re_lu_40 (ReLU)              (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_40 (MaxPooling (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_43 (Conv2D)           (None, 14, 14, 32)        9248      \n",
      "_________________________________________________________________\n",
      "re_lu_41 (ReLU)              (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_41 (MaxPooling (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_44 (Conv2D)           (None, 7, 7, 32)          9248      \n",
      "_________________________________________________________________\n",
      "re_lu_42 (ReLU)              (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_42 (MaxPooling (None, 3, 3, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_45 (Conv2D)           (None, 3, 3, 10)          2890      \n",
      "_________________________________________________________________\n",
      "re_lu_43 (ReLU)              (None, 3, 3, 10)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_43 (MaxPooling (None, 1, 1, 10)          0         \n",
      "_________________________________________________________________\n",
      "flatten_15 (Flatten)         (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "softmax_3 (Softmax)          (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 21,706\n",
      "Trainable params: 21,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Fourth convolutional model\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# convolutional layers\n",
    "model.add(Conv2D(input_shape=IMG_SHAPE,\n",
    "                 filters=32, kernel_size=3, strides=1, padding='same'))\n",
    "model.add(ReLU())\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Conv2D(filters=32, kernel_size=3, strides=1, padding='same'))\n",
    "model.add(ReLU())\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Conv2D(filters=32, kernel_size=3, strides=1, padding='same'))\n",
    "model.add(ReLU())\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Conv2D(filters=10, kernel_size=3, strides=1, padding='same'))\n",
    "model.add(ReLU())\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "\n",
    "# dense layers to consolidate information\n",
    "model.add(Flatten())\n",
    "model.add(Softmax())\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_27\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_76 (Conv2D)           (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "re_lu_64 (ReLU)              (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_74 (MaxPooling (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_77 (Conv2D)           (None, 14, 14, 64)        18496     \n",
      "_________________________________________________________________\n",
      "re_lu_65 (ReLU)              (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_75 (MaxPooling (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_78 (Conv2D)           (None, 7, 7, 128)         73856     \n",
      "_________________________________________________________________\n",
      "re_lu_66 (ReLU)              (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_76 (MaxPooling (None, 3, 3, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_27 (Flatten)         (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 128)               147584    \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_58 (Dense)             (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 249,162\n",
      "Trainable params: 249,162\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# fifth model\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# convolutional layers\n",
    "model.add(Conv2D(input_shape=IMG_SHAPE,\n",
    "                 filters=32, kernel_size=3, strides=1, padding='same'))\n",
    "model.add(ReLU())\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Conv2D(filters=64, kernel_size=3, strides=1, padding='same'))\n",
    "model.add(ReLU())\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Conv2D(filters=128, kernel_size=3, strides=1, padding='same'))\n",
    "model.add(ReLU())\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "# dense layers to consolidate information\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=128, activation='tanh'))\n",
    "model.add(Dense(units=64, activation='tanh'))\n",
    "\n",
    "# output layer to make the final decision on which number it is\n",
    "model.add(Dense(units=NUM_CLASSES, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_54\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_155 (Conv2D)          (None, 10, 10, 16)        160       \n",
      "_________________________________________________________________\n",
      "re_lu_143 (ReLU)             (None, 10, 10, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_156 (Conv2D)          (None, 4, 4, 8)           1160      \n",
      "_________________________________________________________________\n",
      "re_lu_144 (ReLU)             (None, 4, 4, 8)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_157 (Conv2D)          (None, 1, 1, 10)          1290      \n",
      "_________________________________________________________________\n",
      "re_lu_145 (ReLU)             (None, 1, 1, 10)          0         \n",
      "_________________________________________________________________\n",
      "flatten_53 (Flatten)         (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_103 (Dense)            (None, 10)                110       \n",
      "=================================================================\n",
      "Total params: 2,720\n",
      "Trainable params: 2,720\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# sixth model\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# convolutional layers\n",
    "model.add(Conv2D(input_shape=IMG_SHAPE,\n",
    "                 filters=16, kernel_size=3, strides=3, padding='same'))\n",
    "model.add(ReLU())\n",
    "model.add(Conv2D(filters=8, kernel_size=3, strides=3, padding='same'))\n",
    "model.add(ReLU())\n",
    "model.add(Conv2D(filters=10, kernel_size=4, strides=4, padding='same'))\n",
    "model.add(ReLU())\n",
    "\n",
    "# dense layers to consolidate information\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=NUM_CLASSES, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      " 752/1875 [===========>..................] - ETA: 1s - loss: 0.1671"
     ]
    }
   ],
   "source": [
    "# keras requires a color dimension, so we need to expand each image to have one\n",
    "images_3d_train = numpy.expand_dims(images_train, axis=3)\n",
    "\n",
    "# the labels need to be one-hot encoded, to match the ten outputs of our model\n",
    "labels_onehot_train = to_categorical(labels_train)\n",
    "\n",
    "# set up the model to be ready for training\n",
    "model.compile(optimizer=SGD(learning_rate=0.01, nesterov=True), loss='categorical_crossentropy') # originally categorical_crossentropy\n",
    "\n",
    "# fit the model to the training data\n",
    "model.fit(images_3d_train, labels_onehot_train, epochs=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras requires a color dimension, so we need to expand each image to have one\n",
    "images_3d_test = numpy.expand_dims(images_test, axis=3)\n",
    "\n",
    "# get the predictions from the model\n",
    "predictions_test_onehot = model.predict(images_3d_test)\n",
    "\n",
    "# get the index that has the highest probability\n",
    "predictions_test = numpy.argmax(predictions_test_onehot, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9394"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the overall accuracy\n",
    "accuracy_score(y_true=labels_test, y_pred=predictions_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.93210475, 0.9901168 , 0.87280702, 0.98245614, 0.92941176,\n",
       "        0.90531915, 0.96753247, 0.97752809, 0.88415842, 0.96348013]),\n",
       " array([0.98061224, 0.97092511, 0.96414729, 0.88712871, 0.96537678,\n",
       "        0.95403587, 0.93319415, 0.93093385, 0.91683778, 0.88899901]),\n",
       " array([0.95574341, 0.98042705, 0.91620626, 0.93236212, 0.94705295,\n",
       "        0.9290393 , 0.95005313, 0.95366218, 0.90020161, 0.92474227]),\n",
       " array([ 980, 1135, 1032, 1010,  982,  892,  958, 1028,  974, 1009]))"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get precision, recall, f-score, and number of examples of each digit\n",
    "# can you see which digits are easiest for the model, and which are hardest?\n",
    "precision_recall_fscore_support(y_true=labels_test, y_pred=predictions_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter path: model_1_2\n",
      "INFO:tensorflow:Assets written to: ./model_1_2/assets\n"
     ]
    }
   ],
   "source": [
    "# save model as local file!\n",
    "\n",
    "model.save('./' + input('Enter path: '))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "Can you get the model to perform better? Try adding more layers, or taking them away. \n",
    "Take a look at the documentation for the [convolutional](https://keras.io/layers/convolutional/) and [dense](https://keras.io/layers/core/) layers and the [sequential model](https://keras.io/models/sequential/) to understand the options that you have and try out different things.\n",
    "\n",
    "It might also be a good idea to find examples posted online of networks that did well with MNIST and try out some of the configuration they used. Make sure you cite any sources you use!\n",
    "\n",
    "Take notes of what performance you get from different configurations.\n",
    "\n",
    "Comment on what patterns you observed in terms of what changes helped your model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modifications\n",
    "\n",
    "#### Model 1\n",
    "\n",
    "I completely reworked the architecture of the given convolutional neural network as follows (13570 trainable parameters):\n",
    "- Add **ReLU activation functions** after the **two convolutional layers** (see code for details)\n",
    "  - This adds a non-linearity to the convolutional layers and filters out noise to keep only the *positive* filter-image combinations\n",
    "- Decrease the **stride** of each convolutional layer from 2 to 1\n",
    "- Add a two-dimensional **max-pooling** layer (2x2 by default) after each ReLU activation in the convolutional part of the network\n",
    "  - Decreases the size of the input to the second layer while emphasizing *maximum* first-layer output (which is what we are aiming for—higher activations of a given filter should be propagated over \"adjacent noise\")\n",
    "- Increase the number of units in the **hidden layer** of the feed-forward section from 8 to 32.\n",
    "\n",
    "These changes allowed me to achieve 93.56% accuracy (see the `mnist_model` folder) on the MNIST dataset—further details regarding F1 score, precision, and recall can be found above.\n",
    "\n",
    "#### Model 2\n",
    "\n",
    "I also built a model with a similar complexity (in terms of number of trainable parameters) to the originally provided example—decreasing training time by approximately 30%, reducing the number of trainable parameters from 3898 to 3058, and improving accuracy by approximately 25% (from ~49% to ~75%). Changes were as follows:\n",
    "\n",
    "- Add **ReLU activation functions** after the single convolutional layer\n",
    "  - This adds a non-linearity to the convolutional layers and filters out noise to keep only the *positive* filter-image combinations\n",
    "- Add a two-dimensional **max-pooling** layer (4x4) after the ReLU activation in the convolutional part of the network\n",
    "  - Decreases the size of the input to the second layer while emphasizing *maximum* first-layer output (which is what we are aiming for—higher activations of a given filter should be propagated over \"adjacent noise\")\n",
    "- Increase the number of units in the **hidden layer** of the feed-forward section from 8 to 64.\n",
    "- Decrease the **number of filters** in the convolutional layer from 8 to 4.\n",
    "\n",
    "#### Model 3\n",
    "\n",
    "It also turns out that stacking 4 convolutional layers with 16 filters each (total of 7290 trainable parameters) with ReLU activation and 2x2 max-pooling can produce a fairly good accuracy of 91.89% (see the `stack_conv_layers` model folder). See the code for more details.\n",
    "\n",
    "#### Model 4\n",
    "\n",
    "Weird observation here, but when you just stack 4 convolutional layers (with the first 3 having 16 filters) and have the last layer with ten filters (then flatten > softmax those filter outputs), you can achieve extremely high accuracy (96.32%) with only 6250 trainable parameters—see the `10_filters` model folder and the code above for implementation details.\n",
    "\n",
    "#### Model 5\n",
    "\n",
    "Extending model 1 by adding more filters (a lot!) and providing more convolutional layers increased accuracy to approximately 97.92%—see the code for implementation details. During testing, I tried reducing the filter size to 2x2 (from 3x3), and this completely prevented the model from learning anything—accuracy dropped to ~11.3% at this point, which is barely above random guessing. There were"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
