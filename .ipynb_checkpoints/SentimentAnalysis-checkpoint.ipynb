{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis on the Sentiment140 dataset using Multinomial Naive Bayes and LSTMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset was acquired from the [Sentiment140](http://help.sentiment140.com/for-students) website.\n",
    "\n",
    "## 1. Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>polarity</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>query</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2243077421</td>\n",
       "      <td>Fri Jun 19 12:59:52 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>urbanko</td>\n",
       "      <td>I just screamed 'daffodils!!! Ahhhh!!!' and mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2070002870</td>\n",
       "      <td>Sun Jun 07 16:55:37 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>butterbeckafly</td>\n",
       "      <td>petted the stingrays at the zoo and ate delici...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2321629940</td>\n",
       "      <td>Wed Jun 24 21:20:00 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>davidlian</td>\n",
       "      <td>@nikicheong The only way I've done it is the m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1979916623</td>\n",
       "      <td>Sun May 31 05:00:54 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>DigitalJedi007</td>\n",
       "      <td>I STILL can't believe it...why do I even attem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1972805441</td>\n",
       "      <td>Sat May 30 09:55:19 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>hawkins_boi</td>\n",
       "      <td>ohhhhhhhhhhh i hope i make it home in time  fo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   polarity          id                          date     query  \\\n",
       "0         0  2243077421  Fri Jun 19 12:59:52 PDT 2009  NO_QUERY   \n",
       "1         4  2070002870  Sun Jun 07 16:55:37 PDT 2009  NO_QUERY   \n",
       "2         0  2321629940  Wed Jun 24 21:20:00 PDT 2009  NO_QUERY   \n",
       "3         0  1979916623  Sun May 31 05:00:54 PDT 2009  NO_QUERY   \n",
       "4         0  1972805441  Sat May 30 09:55:19 PDT 2009  NO_QUERY   \n",
       "\n",
       "             user                                               text  \n",
       "0         urbanko  I just screamed 'daffodils!!! Ahhhh!!!' and mo...  \n",
       "1  butterbeckafly  petted the stingrays at the zoo and ate delici...  \n",
       "2       davidlian  @nikicheong The only way I've done it is the m...  \n",
       "3  DigitalJedi007  I STILL can't believe it...why do I even attem...  \n",
       "4     hawkins_boi  ohhhhhhhhhhh i hope i make it home in time  fo...  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB # we need this for our Naive Bayes model\n",
    "\n",
    "# These next two are about processing the data. We'll look into this more later in the semester.\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "import sklearn.metrics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Determine class names\n",
    "class_names = [0,2,4]\n",
    "\n",
    "# Read the data from the CSV file provided.\n",
    "data = pd.read_csv(\"/Users/bracho/Downloads/trainingandtestdata/training.1600000.processed.noemoticon.csv\",\n",
    "                   encoding=\"ISO-8859-1\",\n",
    "                   names=[\"polarity\", \"id\", \"date\", \"query\", \"user\", \"text\"])\n",
    "\n",
    "data = data.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the text into numbers that represent each word (bag of words method)\n",
    "word_vector = CountVectorizer()\n",
    "word_vector_counts = word_vector.fit_transform(list(data[\"text\"]))\n",
    "\n",
    "# Account for the length of the documents:\n",
    "#   get the frequency with which the word occurs instead of the raw number of times\n",
    "term_freq_transformer = TfidfTransformer()\n",
    "term_freq = term_freq_transformer.fit_transform(word_vector_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the Naive Bayes model\n",
    "model = MultinomialNB().fit(term_freq, list(data[\"polarity\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now test the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RECALL: [0.83050847 0.         0.76373626]\n",
      "PRECISION: [0.66818182 0.         0.5       ]\n",
      "F1 SCORE: [0.74055416 0.         0.60434783]\n"
     ]
    }
   ],
   "source": [
    "test = pd.read_csv(\"/Users/bracho/Downloads/trainingandtestdata/testdata.manual.2009.06.14.csv\",\n",
    "                   encoding=\"ISO-8859-1\",\n",
    "                   names=[\"polarity\", \"id\", \"date\", \"query\", \"user\", \"text\"])\n",
    "\n",
    "test_counts = word_vector.transform(list(test[\"text\"]))\n",
    "test_term_freq = term_freq_transformer.transform(test_counts)\n",
    "    \n",
    "test_pred = model.predict(test_term_freq)\n",
    "test_actual = list(test[\"polarity\"])\n",
    "test_actual\n",
    "\n",
    "print(\"RECALL:\", sklearn.metrics.recall_score(test_actual, test_pred, average=None))\n",
    "print(\"PRECISION:\", sklearn.metrics.precision_score(test_actual, test_pred, average=None))\n",
    "print(\"F1 SCORE:\", sklearn.metrics.f1_score(test_actual, test_pred, average=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.43264136 0.56735864]]\n"
     ]
    }
   ],
   "source": [
    "fd_input = [\n",
    "    'the sentiment140 dataset is a great tool']\n",
    "\n",
    "def predictions(fake_docs):\n",
    "    fake_counts = word_vector.transform(fake_docs)\n",
    "    fake_term_freq = term_freq_transformer.transform(fake_counts)\n",
    "\n",
    "    predicted = model.predict_proba(fake_term_freq)\n",
    "    print(predicted)\n",
    "\n",
    "predictions(fd_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. LSTMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential, load_model, Model\n",
    "from keras.layers import Conv2D, BatchNormalization, Activation, Dropout, MaxPooling2D, Conv2DTranspose, UpSampling2D, Flatten, Dense, Reshape, Conv1D, MaxPooling1D, PReLU, Input, TimeDistributed, LSTM, Embedding\n",
    "from keras.optimizers import Adam\n",
    "from keras import regularizers\n",
    "import keras.backend as K\n",
    "from scipy.sparse import csr_matrix\n",
    "import re\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_convert(tx):\n",
    "    tx = re.sub(r'[^0-9a-zA-Z ]+', '', tx).split()\n",
    "    v = csr_matrix(w_vector.transform(tx)).todense()\n",
    "    v = np.where(v==1)[1]+1\n",
    "    v = np.pad(v, (0, 100-len(v)), 'constant')\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorize the words in the dataset\n",
    "# Convert the text into numbers that represent each word (bag of words method)\n",
    "w_vector = CountVectorizer(max_features=10000)\n",
    "w_vector_counts = w_vector.fit_transform(list(data[\"text\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 100)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_vectorized = []\n",
    "for text in list(data[\"text\"])[:10000]:\n",
    "    data_vectorized.append(text_convert(text))\n",
    "\n",
    "data_vectorized = np.array(data_vectorized)\n",
    "data_vectorized.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model = Sequential()\n",
    "inputs = Input(shape=(100,))\n",
    "embedding = Embedding(10001, 100, input_length=100)(inputs)\n",
    "lstm1, state_h1, state_c1 = LSTM(128, return_state=True, return_sequences=True)(embedding)\n",
    "lstm2, state_h2, state_c2 = LSTM(128, return_state=True)(lstm1)\n",
    "dense_1 = Dense(1024)(state_h2)\n",
    "dense_output = Dense(1)(dense_1)\n",
    "output_tanh = Activation(\"tanh\")(dense_output)\n",
    "lstm_model = Model(inputs=inputs, outputs=[output_tanh])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "100/100 [==============================] - 4s 41ms/step - loss: 0.5156 - mean_squared_error: 1.0021\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1906bd690>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = keras.optimizers.Adadelta()\n",
    "\n",
    "lstm_model.compile(optimizer=optimizer, loss=\"binary_crossentropy\", metrics=[\"mse\"])\n",
    "lstm_model.fit(data_vectorized, list((data[\"polarity\"]-2)/2)[:10000], epochs=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.10848051]], dtype=float32)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_model.predict(np.array([text_convert(\"I hated the movie I watched yesterday it was so bad\")]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
